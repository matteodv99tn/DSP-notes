\chapter{Continuous and discrete time Fourier Transform}
	
	The \de{Fourier transform} $\F$ is an operator that allow to express a signal $x$ (originally dependent from the time $t$) in the \textbf{frequency domain} $\Omega,\omega$; this is somewhat related to the Fourier series, but with the unique difference that the series expansion is a technique in time domain, while the transform translate the signal into the frequency domain.
	
	The analytical definition of the transform is different if the signal $x(t)$ is continuous in time, and thus using an integral definition, or is a discrete time function $x(n)$ (infinite sum definition):
	\begin{equation} \label{eq:four:trasfdef}
		X(\Omega) := \int_{-\infty}^{\infty} x(t) e^{-j\Omega t} \, dt \quad \in \mathds C \qquad X\left(e^{j\omega}\right) := \sum_{\infty}^{n = - \infty} x(n) e^{-j\omega n}
	\end{equation}
	The first case is known as the \de{continuous Fourier transform}, while the other is the \de{discrete Fourier transform}, but essentially they are used to perform the same operation (for continuous or discrete time domains). The formal difference between the variables $\Omega$ and $\omega$ is that the first measures a $rad/s$, while the unit of $\omega$ is just radians $rad$: this is due to the fact that $n$ is an integer number and considering that $x(n)$ is sampled with a period $T_s$ we can see the relation $\omega = \Omega T_s$ in the discrete time case. Usually it's easier to describe the transform of a discrete signal in terms of $\omega$ (in respect to $\Omega$) because this expression it's independent of the sampling time $T_s$.
	
	The result of a transform is called \de{spectrum} and it's a complex sequence/function that usually is decomposed in it's \textbf{magnitude} and \textbf{phase}. 
	
	In general signal in the time domains are described by a lower case letter (such $x$) while their relative transform are describe by an upper case letter (so $X(\Omega) = \four{x(t)}$).
	
	\paragraph{Inverse transform} Every time we have a transform (like $X(\Omega)$), an important operation that we might want to perform is the \de{inversion} that allow to reconvert the spectrum of the signal into a function in the time domain. Analytically this can be done by using the following formal definition of \de{inverse Fourier transform} (for both continuous and discrete cases):
	\begin{equation}
		x(t) := \frac 1 {2\pi} \int_{-\infty}^\infty X(\Omega) e^{j\Omega t} \, d\Omega \qquad x(n) = \frac 1{2\pi} \int_{-\pi}^\pi X\left(e^{j\omega}\right) e^{j\omega n}\, d\omega
	\end{equation}
	Note that the spectrum of a discrete time function, even if the domain in time is discrete, is continuous; another aspect to point out is that the discrete inverse Fourier transform integrates the spectrum only in the range $[-\pi,\pi]$: this is due the fact that integrating a periodic function of period $2\pi$ in a wider range won't give any benefit in terms of featured extracted from the signal.

	\paragraph{Relationship with other transforms} The Fourier transform is related to the Laplace transform defined as
	\[x(t) \xrightarrow{\mathscr{L}} X(s) := \int_{-\infty}^\infty x(t) e^{-st} \, dt \]
	where $s = \sigma + j\omega \in \mathds C$ is a complex variable. In general if the Laplace transform of a function exists, also the Fourier counter-part exists, because we can see the Fourier transform as
	\[ X(\Omega) = X(s) \big|_{s = j\Omega} \]
	so it's the frequency axes of the complex plane of the Laplace transform. In reality some function can have the Fourier transform even if the Laplace one cannot be computed.
	
	In the discrete time case the relation is between the Z transform $\mathscr{Z}$ defined as
	\[x(n) \xrightarrow{\mathscr{Z}} X(z) = \sum_{n=-\infty}^{\infty} x(n) z^{-n}  \qquad z \in \mathds C \]
	where $z$ is a complex variable. Comparing this transform with the discrete-time Fourier one, we can see that by replacing $z$ as $e^{j\omega}$ we can see that they are equal:
	\[ X\left(e^{j\omega} \right) = X(z) \big|_{z = e^{j\omega}} \]
	Considering that $|e^{j\omega}| = 1 \ \forall \omega$, this means that $e^{j\omega}$ represent a circle in the complex plane with unitary radius and $\omega$ is the angle that describes the point in the circle.
	
	\paragraph{Existence conditions of the Fourier transform} In general there's no guarantee that the integral/sum converges in order to get the transform; in particular we can define the \textbf{sufficient condition} (but not necessary) that says that if the signals $x(t), x(n)$ are absolutely summable (such that $\int_{-\infty}^\infty |x(t)|\, dt < \infty$, $\sum_{n=-\infty}^\infty |x(n)| < \inf $) then $X(\Omega), X(e^{j\omega})$ exists.
	\begin{proof}
		To prove this sufficient condition for the continuous time case, we need to consider that
		\begin{align*}
			|X(\Omega)| = \left| \int_{-\infty}^\infty x(t) e^{-j\Omega t}\, dt \right| \leq \int_{-\infty}^\infty |x(t)|\underbrace{ \left|e^{-j\Omega t}\right|}_{=1} \, dt
		\end{align*}
		So if the integral of $|x(t)|$ converges, also the Fourier transform exists.
	\end{proof}
	
	It's possible to have function that are not absolutely summable but for which the Fourier transform exists.
	
	\begin{example}{: anti-transform of a rectangle spectrum}
		Let's consider a function whose transform is described by a rectangular distribution $X(\Omega) = \rect_{2\Omega_c}(\Omega)$ (where $\Omega_c = 2\pi f_c$); in order to \textit{read} the function in the time domain we need to calculate the inverse Fourier transform of the signal and so
		\begin{align*}
			\antifour{\rect_{2\Omega_c}(\Omega)}(t) & = \frac 1{2\pi} \intinf X(\Omega) e^{j\Omega t} \, d\Omega = \frac 1 {2\pi} \int_{-\Omega_c}^{\Omega_c} e^{j\Omega t}\, d\Omega \\
			& = \frac{e^{j\Omega_c t} - e^{-j\Omega_c t}}{2\pi j t} = \frac{\sin\big(\Omega_c t\big)}{\pi t} \frac{2f_c}{2f_c} \\ 
			& = 2 f_c \sinc\big(\Omega_c t\big)
		\end{align*}
		This function is an example of a non absolutely summable function (by computing the integral $\intinf 2f_c|\sin(\Omega_c t)| \, dt \rightarrow \infty$ it diverges) but for which the Fourier transform exists.
	\end{example}

	
	A weaker necessary condition for the existence of the Fourier transform is that if $X(\Omega)$ (or $X(e^{j\omega})$) exists, than it's necessary that $x(t) = \lim_{\Omega \rightarrow \infty} \frac 1 {2\pi} \int_{-\Omega}^\Omega X(\Omega) e^{j\Omega} \, d\Omega $, or in a more general way the necessary condition of the existence of the transform is that the energy signal converges to a finite number (and so it's not divergent).
	
	\paragraph{Relationship between Fourier transform and series} 
	The Fourier transform and series are related, but are two different things: the \textbf{series} is the composition in the \textbf{time domain} of the components of the signal, while the \textbf{transform} changes the shape of the signal from time to \textbf{frequency domain}.
	
	By expressing the Fourier series with the complex notation
	\[ c_m = \frac 1 T \int_{-T/2}^{T/2} x(t) e^{-\frac{2\pi j m t}{T} } \, dt \]
	where $x(t)$ is a periodic function with period $T$; if we extract the signal in a period as
	\[\tilde x(t) = \begin{cases}
		x(t) \qquad & t \in [-T/2,T/2] \\ 0 & \textrm{otherwise}
	\end{cases} \]
	\[ \Rightarrow \quad \tilde X(\Omega) = \int_{-\infty}^{\infty} \tilde x(t) e^{-j\Omega t} dt = \int_{-T/2}^{T/2} \tilde x(t) e^{-j\Omega t} dt \]
	This equation allows us to express the coefficients $c_m$ by using the Fourier transform.
	
	
\section{Property of the transform}
	
	Digital signal processing involves a lot of spectral analysis, and so it's important to understand the most important properties of the transform and hence the signals in the frequency domain. In the following paragraph the properties described (while not otherwise specified) are meant to work both on discrete and continuous Fourier transform.
	
	\paragraph{Linearity} The Fourier transform is a \textbf{linear operator}, so for every signals $x_1(t),x_2(t)$ that gave a transform associated $X_1(\Omega),X_2(\Omega)$ and for every coefficients $a,b\in \mathds R$ it's always true that
	\begin{equation}
		\mathscr{F} \big\{ a x_1(t) + b x_2(t) \big\} = a \mathscr{F}\big\{x_1(t)\big\} + b \mathscr{F}\big\{x_2(t)\big\}
	\end{equation}
	\begin{proof}
			\begin{align*}
				\int_{-\infty}^\infty \Big(a x_1 (t) + bx_2(t)\Big) e ^{-j\Omega t} \, dt = a \int_{-\infty}^\infty x_1 (t)  e ^{-j\Omega t} \, dt + b \int_{-\infty}^\infty x_2 (t)  e ^{-j\Omega t} \, dt 
			\end{align*}
	\end{proof}
	
	\paragraph{Time shifting} An important aspect to consider is what happens to a signal $x$ when it's shifted in time by a time $t_0$, so by analysing the signal $x(t-t_0)$: in particular the related spectrum will be described as
	\begin{equation} \label{eq:four:timeshift}
		\four{x(t-t_0)} = e^{-j\Omega t_0} \four{x(t)}
	\end{equation}
	
	\paragraph{Convolution operation} In order to describe the convolution operation, it's important to describe what a \textit{convolution} is. Given two signal $x,h$, their convolution $y$ is defined by the following integral (where $*$ is the convolution operator):
	\begin{equation}
		y(t) = x(t) * h(t) := \int_{-\infty}^\infty x(\tau) h(t-\tau)\, d\tau
	\end{equation}
	Of course this is the definition of a continuous convolution, but the discrete counterpart can be described using the sum definition $y(n) = x(n)*h(n) := \sum_{u=\infty}^\infty x(n) y(n-u)$. \\
	This operation allows us to determine the response of a signal while translating the other in time. The \textbf{convolution property} associated to this operation is so
	\[ \four{x(t) * h(t)} = \four{x(t)} \four{h(t)} \]
		\begin{proof}
			\begin{align*}
				\four{x(t) * h(t)} & = \int_{-\infty}^\infty \left( \int_{-\infty}^\infty x(\tau) h(t-\tau)\, d\tau \right) e^{-j\Omega t} \, dt \\
				& =  \int_{-\infty}^\infty x(\tau) e^{-j\Omega \tau} \underbrace{\left( \int_{-\infty}^\infty h(t-\tau) e^{-j\Omega(t-\tau)} \, dt \right)}_{=\four{h(t)}} \, d\tau \\
				& = H(\Omega) \int_{-\infty}^\infty x(\tau) e^{-j\Omega \tau} \, d\tau = X(\Omega) H(\Omega)
			\end{align*}
		\end{proof}
	
	\paragraph{Differentiation in the frequency domain} Another relevant property/fact is related by a signal whose transform has been differentiated in the frequency domain, and in particular we can note that
	\begin{equation}
		\four{t\, x(t)} = j \frac{d X(\Omega)}{d\Omega} \qquad \four{n \, x(n)} = j \frac{dX(e^{j\omega})}{d\omega}
	\end{equation}
		
		\begin{proof}
		\begin{align*}
			\sum_{n=-\infty}^\infty n x(n) e^{-j\omega n} & = \frac{-j}{-j}\sum_{n=-\infty}^\infty x x(n) e^{-j\omega n} \\
			& = j \sum_{n=-\infty}^\infty x(n) \frac{de^{-j\omega n}}{d\omega} \\
			& = j \frac{d}{d\omega}\sum_{n=-\infty}^\infty x(n) e^{-j\omega n} = j \frac{dX(e^{j\omega})}{d\omega}
		\end{align*}
		\end{proof}
		
	\paragraph{Symmetries} Some notable symmetries can be described while dealing with particular signal; in fact if $x\in \mathds R$ is a real valued signal (no complex values) it's possible to note the following symmetries in the frequency domain:
	\begin{equation}
		X(-\Omega) = X^*(\Omega) \qquad X\big(e^{-j\omega}\big) = X^*\big(e^{j\omega}\big)
	\end{equation}
		\begin{proof}
		\begin{align*}
			X(-\Omega) & = \int_{-\infty}^\infty x(t) e^{-j (-\Omega) t} \, dt = \int_{-\infty}^\infty x(t) \left(e^{-j\Omega t}\right)^* \, dt \\ 
			& = \left( \int_{-\infty}^\infty x(t) e^{-j\Omega t} \, dt\right)^* = X^*(t)
		\end{align*}
		\end{proof}
		From this property we can state that the \textbf{magnitude spectrum} $|x(\cdot)|$ (and so the real part of the spectrum) is always an even function, while the \textbf{phase spectrum} $\angle x(\cdot)$ (thus the imaginary part of the spectrum) is an odd function. \vspace{3mm}
		
		As corollary to this property is that if the function $x(t)$ is real and even, it happens that $X(-\Omega) = X(\Omega)$ and the transform it's also inside the real domain (not the complex one).
		\begin{proof}
			Given the even function $x(t) \in \mathds R$ we can write the proper transform definition by using the Euler relation and so
			\begin{align*}
				X(\Omega) & = \int_{-\infty}^\infty x(t) \overbrace{\big(\cos(\Omega t) + \cancel{j \sin(\Omega t)}\big)}^{e ^{-j\Omega t}} \, dt 
			\end{align*}
			Due to the fact that for an even function only the cosine part of the $e^{j\Omega}$ remains, this means that also the spectrum is real.
		\end{proof}
		Instead if the real function $x(t)$ is odd, than the spectrum $X(\Omega)$ is purely imaginary.
		\begin{proof}
			Given the even function $x(t) \in \mathds R$ we can write
			\begin{align*}
				X(\Omega) & = \int_{-\infty}^\infty x(t) \overbrace{\big(\cancel{\cos(\Omega t)} + {j \sin(\Omega t)}\big)}^{e ^{-j\Omega t}} \, dt 
			\end{align*}
			Due to the fact that for an odd function only the sine part of the $e^{j\Omega}$ remains, this means that also the spectrum is real.
		\end{proof}
		In general every real function $x(t)$ can be decomposed into two function: an even one $x_e$ and a odd one $x_o$ defined as
		\[ x_e(t) = \frac{x(t)+x(-t)}{2} \qquad x_o = \frac{x(t)-x(-t)}{2} \qquad \Rightarrow \quad x(t) = x_e(t)+ x_o(t) \]
		This means that the spectrum of every function can be subdivided in a only real part (associated to $x_e$) and a purely imaginary part (associated to $x_o$):
		\[ X(\Omega) = \int_{-\infty}^\infty x_e(t) \cos(\Omega t) \, dt + j \int_{-\infty}^\infty x_o(t)\, \sin(\Omega t)\, dt = X_e(\Omega) - j X_o(\Omega)\]
	
		\paragraph{Time reversal} Another aspect of the Fourier transform is the time reversal property that states that if a signal $x$ is reversed in time (so calculating $x(-t)$ or $x(-n)$ in the discrete time case), the relative spectrum is equal to the conjugate of the starting signals:
		\begin{equation}
			\four{x(-t)} = X^*(-\Omega) \qquad \four{x(-n)} =X^*(e^{-j\omega})
		\end{equation}
		In particular using the symmetries previously described if the signal is real it also happens that $\four{x(-t)} = X^*(\Omega)$.
		\begin{proof}
			Dimostrazione mediante cambio di variable.
		\end{proof}
		
		\paragraph{Windowing theorem} Assume having 2 signals $x(t),w(t)$ (or $x(n), w(n)$ ) that produces the signal $y(t) = x(t) \, w(t)$ (note that this is not a linear operation), then the corresponding Fourier transform is the convolution (in the frequency domain) of the transforms:
		\begin{equation} \label{eq:four:windowing}
		\begin{split}
			\four{x(t)w(t)} & = Y(\Omega) = X(\Omega)*W(\Omega) = \frac 1 {2\pi} \int_{-\infty}^{\infty} X(\Theta) W(\Omega - \Theta)\, d\Theta \\
			\four{x(n)w(n)} & =  Y(e^{j\omega}) = X(e^{j\omega}) * W(e^{j\omega}) = \frac 1 {2\pi} \int_{-\pi}^\pi X(e^{j\theta}) W(e^{j(\omega-\theta)}) \, d\theta
		\end{split}
		\end{equation}
		
		This is important because when we analyse a signal, we are analysing only one portion (in time) of the signal itself, we never can scan the full length of the signal. Analytically speaking analysing the signal $x(t)$ in a certain range $T$ can be seen as the product of the full $x$ signal with a rectangle signal $w$ with value 1 in the sampling range and 0 elsewhere. In a practical way this means that by analysing only a set of the signal $x$ (and not the full one), we introduce a distortion (due to $w$) that can be \textit{measured} in the frequency domain with the convolution operation.
		
		\begin{proof}
		\begin{align*}
			\sum_{n=-\infty}^\infty x(n) w(n) e^{-j\omega n} & = \sum_{n=-\infty}^\infty w(n) \left( \frac 1 {2\pi} \int_{-\pi}^\pi x\big(e^{j\theta}\big) e^{j\theta n} \, d\theta \right) e^{-j\omega n} \\
			& = \frac 1 {2\pi} \int_{-\pi}^\pi \left( X\big(e^{j\theta}\big) e^{j\theta n} \sum_{n=-\infty}^\infty w(n) e^{-j\omega n} \right) \, d\theta \\
			& = \frac 1 {2\pi} \int_{-\pi}^\pi \left( X\big(e^{j\theta}\big)  \sum_{n=-\infty}^\infty w(n) e^{-j(\omega-\theta) n} \right) \, d\theta \\
			& = \frac 1 {2\pi} \int_{-\pi}^\pi X\big(e^{j\theta}\big) W \big(e^{j(\omega - \theta)}\big) \, d\theta
		\end{align*}
		\end{proof}
		An important corollary to this property is the \textbf{Parsevals's theorem} that states that given two signals $x,y$, than it happens that
		\begin{equation}
			\four{\int_{-\infty}^\infty x(t) y^* (t)\, dt} = \frac 1 {2\pi} \int_{-\infty} ^\infty X(\Omega) Y^*(\Omega)\, d\Omega
		\end{equation}
		This is useful because if we calculate $\int_{-\infty}^\infty x(t)x(t)\, dt$ we get that the energy of the signal can be calculated also in the frequency domain.
		
		 \paragraph{Correlation} To measure the \textit{similarity} (in the time domain) of two signals $x,y$ it's possible to use the \textbf{correlation operator} $\otimes$ defined as follows:
		\begin{equation}
			x(t) \otimes y(t) = \int_{-\infty}^\infty x(\tau) y^*(t+\tau)\, d\tau = x(t)*y^*(-t) 
		\end{equation}
		Note that in general if we calculate the correlation between the same function ($x\otimes x$), that measures the \textbf{autocorrelation}.
		
		In general we can use the property of the transform of a correlated signal as
		\begin{equation}
			\four{x(t)\otimes y(t)} = \frac 1{2\pi} \int_{-\infty}^\infty X(\Omega) Y^*(\Omega) e^{j\Omega t} \, d\Omega
		\end{equation}
		The proof of this property can be done by using the Parsevals's theorem.
	
	
\section{Transforms of standard functions}
	
	\paragraph{Pulse transform} Considering the Dirac pulse $\delta(t)$, it's transform can be perform by computed considering the property of this particular distribution for which $\intinf g(t)\delta(t)\, dt = g(0)$; by applying the proper definition of the Fourier transform the resultant spectrum is
	\begin{align*}
	\begin{split}
		\four{\delta(t)} & = \intinf \delta(t) e^{-j\Omega t}  \, dt = e^{-j\Omega 0} \\ & = 1
	\end{split}
	\end{align*}
	By using the  time shifting property (eq \ref{eq:four:timeshift}, page \pageref{eq:four:timeshift}) we can compute the transform of a Dirac pulse occurring on time $t = t_0$ as $\four{\delta(t-t_0)} = e^{-j\Omega t_0}$, so it's a rotation in the complex plane by an angle $\Omega t_0$.
	
	\paragraph{Rectangular and constant signal} Let's consider the rectangular signal with parameter $\tau$ described on page \pageref{eq:intro:rect} by the function $\rect_\tau$, we can compute it's transform by applying the Fourier transform definition:
	\begin{align*}
			\four{A \, \textrm{rect}_\tau(t)}	& =	 A \int_{-\tau/2}^{\tau/2} e ^{-j\Omega t} \, dt = \frac \tau 2 A \frac{e^{-j\Omega \tau/2} - e^{j\Omega \tau/2}}{-j\Omega \frac \tau 2} \\ & = A \tau \sinc (\Omega \tau/2) \\
			\four{a} & = a \, \delta(\Omega)
	\end{align*}
	
	By pushing the limit for the parameter $\tau$ that tends to infinity we can see that the function represent the constant signal $x(t) = 1$ whose transform is
	\begin{align*}
		\four{1} & = \lim_{\tau\rightarrow \infty} \four{\rect_\tau(t)} = \lim_{\tau\rightarrow \infty} \tau \sin\left(   \frac{\Omega \tau}{2}\right) \\ & = \delta(\Omega)
	\end{align*}
	By pushing the limit we can see that the cardinal sine function $\sinc$ resembles the Dirac delta distribution. At this point we can see a sort of dual relation between the transform of a constant and the transform of the $\delta$ function: in a more general way we can state the \de{duality principle} that states that for each signal $x(t)$ having $X(\Omega)$ as transform it happens that
	\begin{equation}
		X(\Omega) = \four{x(t)} \qquad \Rightarrow \quad \four{X(t)} = x(-\Omega) \quad \textrm{and} \quad \four{x(\Omega)} = X(-t)
	\end{equation}
	
	\paragraph{Harmonic functions} Let's consider now a general co-sinusoidal signal with pulsation $\Omega_0$ and starting phase $\phi_0$ described as $x(t) = A\cos(\Omega_0 t + \phi_0)$. To compute the transform we can apply the formal definition utilizing also the Euler relation to describe the cosine function:
	\begin{align*}
		\four{A \cos\big(\Omega_0 t + \phi_0\big)} & = \intinf A  \cos\big(\Omega_0 t + \phi_0\big) e^{-j\Omega t} \, dt \\ 
		& = \intinf A \left( \frac{e^{j(\phi_0 + \Omega_0 t)} + e^{-j(\phi_0 - \Omega_0t)} }{2} \right) e^{-j\Omega t}\, dt \\
		& = \frac A 2 e^{j\phi_0} \lim_{\tau\rightarrow\infty} \int_{-\tau}^\tau e^{j(\Omega_0-\Omega)t}\, dt + \frac A 2 e^{-j\phi_0} \lim_{\tau\rightarrow\infty} \int_{-\tau}^\tau e^{-j(\Omega_0-\Omega)t}\, dt \\
		& = \frac A 2 e^{j\phi_0} \lim_{\tau\rightarrow\infty} 2\tau \sinc\Big(\big(\Omega-\Omega_0\big)t\Big) + \frac A 2 e^{-j\phi_0} \lim_{\tau\rightarrow\infty} 2\tau \sinc\Big(\big(\Omega-\Omega_0\big)t\Big) \\
		& = \frac A 2 e^{j\phi_0} \delta\big(\Omega - \Omega_0\big) + \frac A 2 e^{-j\phi_0} \delta\big(\Omega + \Omega_0\big)
	\end{align*}
	Similarly it can be proven that the transform a sine function can be expressed as
	\[ \four{A \sin\big(\Omega_0 t + \phi_0\big)} = \frac{A}{2j} e^{j\phi_0} \delta\big(\Omega-\Omega_0\big) - \frac{A}{2j} e^{-j\phi_0} \delta\big(\Omega+\Omega_0\big) \]
	
	This transforms are very useful while dealing with periodic signals (with period $T$): in fact in that case we can use the Fourier series to decompose it in a sum of harmonic signals in the form
	\[ x(t) = \frac{a_0}{2} + \sum_{m=1}^\infty a_m \cos\left( \frac{2\pi m}{T} t \right) + \sum_{m=1}^\infty b_m \sin\left( \frac{2\pi m}{T} t \right) \]
	By computing the Fourier series of this signal we can see that the spectrum of a periodic signal in the time domain is associated to a sequence of pulses (spaced by a pulsation $\Omega_0 = \frac{2\pi}{T}$) in the frequency domain:
	\begin{align*}
		X(\Omega) = &  \frac{a_0}{2} \delta(\Omega) + \sum_{m=1}^\infty\frac{a_m}{2} \left[ \delta\left(  \Omega - \frac{2\pi m}{T} \right) + \delta\left(  \Omega + \frac{2\pi m}{T} \right)\right] \\ & + \sum_{m=1}^\infty\frac{b_m}{2j} \left[ \delta\left(  \Omega - \frac{2\pi m}{T} \right) - \delta\left(  \Omega + \frac{2\pi m}{T} \right)\right] \\
		= & \frac{a_0}{2} \delta(\Omega) + \sum_{m=1}^{\infty} \frac{a_m - j b_m}{2} \left[ \delta\left(  \Omega - \frac{2\pi m}{T} \right) - \delta\left(  \Omega + \frac{2\pi m}{T} \right)\right] 
	\end{align*}
	
	\paragraph{Exponential} Let's consider the signal $x(t)$ defined as a exponential only for the positive time range, so defined as $x(t) = e^{-\alpha t} u(t)$ (so multiplying the exponential for the unit step function described in page \pageref{eq:intro:unitstep}). Necessary condition for the existence of the Fourier transform is that the energy signal doesn't diverge to infinity: this criteria is matched every time $\alpha > 0$ while in the other case the integral of the signal $x(t)$ diverges. Sure to have a \textit{transformable} function it's possible to apply the transform definition and thus
	\begin{align*}
		X(\Omega) & = \intinf e^{-\alpha t} u(t) e^{-j\Omega t}\, dt = \int_0 ^\infty e^{-(\alpha + j\Omega) t} \, dt = - \frac{1}{\alpha + j\Omega} e^{-(\alpha + j\Omega) t} \Big|_0^\infty \\
		& = \frac{1}{\alpha + j\Omega}
	\end{align*}
		
	\paragraph{Unit step} The unit step $u(t)$ (defined as 1 for $t\geq0$ and 0 for $t<0$) has it's own transform that's computed considering the following definition of the signal
	\[ x(t) = u_1(t) + u_2(t) = \frac 1 2 + \frac 1 2 \textrm{sign(t)} \qquad \textrm{sign}(t) = \lim_{\alpha\rightarrow 0}\begin{cases}
		e^{-\alpha|t|} \quad & t \geq 0 \\
		-e^{-\alpha |t|} & t < 0
	\end{cases}\]
	This means that the transform of the unit step can be evaluating (using the linear property) as the sum of the transform of the constant term $u_1$ and the limit exponential $u_2$:
	\begin{align*}
		X(\Omega) & = U_1(\Omega) + U_2(\Omega) = \frac 1 2 \delta(\Omega) + \frac 1 2 \lim_{\alpha\rightarrow 0} \left( \frac{1}{\alpha + j\Omega} - \frac{1}{\alpha - j\Omega} \right)  \\
		& = \frac 1 2 \delta(\Omega) - \frac 1 2 \lim_{\alpha\rightarrow 0}\frac{2j\Omega}{\alpha^2	 + \Omega^2} \\ 
		&= \frac 1 2 \delta(\Omega) + \frac{1}{j\Omega}
	\end{align*}
	
	\paragraph{Amplitude modulation signal} Let's consider a signal $a(t)$ that's modulated by a cosine function this resulting in the function $x(t) = a(t) \cos(\Omega_0t + \phi)$. Seeing that this is a product between two function it's possible to use the windowing theorem (eq. \ref{eq:four:windowing}, page \pageref{eq:four:windowing}) to compute it's transform:
	\begin{align*}
		X(\Omega) & = A(\Omega) * \left( \frac{e^{j\phi}}{2} \delta\big(\Omega-\Omega_0\big) + \frac{e^{-j\phi}}{2}\delta\big(\Omega+\Omega_0\big) \right) \\
		& = \frac{e^{j\phi}}{2} \intinf A(\theta) \delta\Big( \Omega - \big(\theta - \Omega_0\big) \Big) \, d\theta + \frac{e^{-j\phi}}{2} \intinf A(\theta) \delta\Big( \Omega - \big(\theta + \Omega_0\big) \Big) \, d\theta
	\end{align*}
	By applying the definition of the Dirac pulse distribution over the integral we can see that the transform of the signal $x(t)$ is a sort of \textit{division} and \textit{translation} of the spectrum of the signal $A$:
	\[ X(\Omega) = \frac{e^{j\phi}}{2} A\big(\Omega-\Omega_0\big) + \frac{e^{-j\phi}}{2} A\big(\Omega+\Omega_0\big) \]
	
	\paragraph{Phase modulation} \textbf{TO BE REVIEWED}
	
	
	\subsection*{Basic discrete Fourier transforms}
		\paragraph{Kronecker pulse} Given the unit time pulse $\delta (n)$, it's transform is calculated as a duality of the Dirac pulse in the continuous time case and so
		\begin{align*}
			\four{\delta(n)} & = \infsum \delta(n) e^{-j\omega n} = e^{-j\omega 0} \\&= 1 \qquad \forall \omega
		\end{align*}
		Shifting the pulse by $n_0$ time steps we have that it's transform is equal to
		\[ \four{\delta(n-n_0)} = e^{-j\omega n_0}\]
		
		\paragraph{Converging exponential sequence} Let's consider the exponential sequence $x(n) = a^n u(n)$ where $|a| < 1$ in order to have a convergent series; it's transform can be consider as
		\begin{align*}
			X\big(e^{j\omega}\big) & = \infsum a^n e^{-j\omega n} = \infsum \underbrace{\left( a e^{-j\omega} \right)^n}_{b^n} 
		\end{align*}
		We can see that this can be expressed as a geometric series whose limit in general converges to
		\[ \lim_{N\rightarrow 0} \sum_{n=0}^N b^n = \lim_{N\rightarrow 0} \frac{1-b^{N+1}}{1-b} = \frac{1}{1-b} = \frac{1}{1-ae^{-j\omega}} \]
		\textbf{RISCRIVERE MODULO E FASE}
		
		\paragraph{Constant} The transform of the discrete constant function $x(n) = 1$ can be computed as the dual of the Kronecker pulse, nut in a general way can say that
		\[ x(n) = \sum_{k=-\infty}^\infty \delta(n-k) \qquad \xrightarrow{\F} \quad X(e^{j\omega}) = 2\pi \sum_{k=-\infty}^\infty \delta(\omega - 2\pi k) \]
		
		\paragraph{Unit step}
		\[ u(n) \qquad \xrightarrow{\F} \quad \underbrace{\frac{1 }{1-e^{-j\omega}}}_{=\four { \frac 1 2 \textrm{sign}(t)}} + \underbrace{\pi \sum_{k=-\infty}^\infty \delta \big(\omega - 2\pi k\big)}_{=\four{\frac 1 2}} \]
		
		\paragraph{Useful sequence} Later in this course (and in real scenario application) we can have a signal expressed as $x(n) = (n+1) a^n u(n)$; in this case the transform is equal to 
		\[ X(e^{j\omega}) = \four{(n+1)a^n u(n)} = \frac{1}{\big(1-ae^{-j\omega} \big)^2} \]
		and can be computed by considering the differentiation rule of the Fourier transform, in fact
		\begin{align*}
			X(e^{j\omega}) & = \four{a^n u(n)} + \four{n a^n u(n)} = \four{y(n)} + \four{n\, y(n)} \\
			& = \frac{1}{1-a e^{-j\omega}} + j \frac{d}{d\omega} \left(\frac{1}{1-a e^{-j\omega}}\right) = \frac{1}{\big(1-ae^{-j\omega} \big)^2}
		\end{align*}
	
		Another remarkable example of sequence present in the real life is the one defined as
		\[ x(n) = r^n \frac{\sin\omega_p(n+1)}{\sin\omega_p} \qquad \xrightarrow{\F} \quad \frac{1}{1 - 2 r\cos\omega_p e^{-j\omega} + e^2 e^{-j2\omega} }   \]
		\[ x(n) e^{j\omega_0 n}  \qquad \xrightarrow{\F} \quad2\pi \infsum \delta \big(\omega - \omega_0 + 2\pi n\big) \]
		
		\textbf{RIVEDERE TRSFORMATA SENO E COSENO}
		
\section{Practical application: gearbox frequency spectrum}
	In mechanical systems are often used gears to transmit rotational power from a shaft to another; usually the shaft are modelled as ideal component where the torque is constantly transmitted from the pinion to the wheel (depending on the radius of the gears in order to satisfy the relation $r_1 \omega_1 = r_2 \omega_2$) by generating a certain force on the contact point.
	
	\textbf{IMMAGINE}
	
	However that description is ideal because it doesn't take into account the real way on how the gears transmit the power that's done by a contact of two sliding teeth, one for each gear. This contact generates the force that, in relation to the centres of the gears, transmit the torque between the shafts; the force transmitted during the contact is not constant in time: the first contact point will in fact determine a high force while later on, when the two teeth slides one relative to the other, the force drops. This represent a cyclic phenomena that can be described as a periodic signal (assuming that the two gears are rotating at a constant speed).
	
	\textbf{IMMAGINE GRAFICO TRASMISSIONE FORZA}
	
	In a practical way, in order to improve the smoothness of the force transmission between the teeth of the gears it should increase the \textbf{profile contact ratio} $\varepsilon_a$ ($1\leq \varepsilon_a < 2$) that represent the number of teeth of that are touching at any time during the motion.
	
	The fact that the torque between the shaft is not transmitted constantly enhance the mechanical vibration of the system;  in particular known the period $T$ of the cyclic transmission of the force we can compute the \textbf{fundamental gear meshing frequency} $\Omega_{gmf}$ as $n \Omega_0$, where $n$ is the number of teeth in a gear rotating at a constant velocity $\Omega_0$. By now analysing the spectrum of the torque transmitted we can see that, other then the always present noise, there are impulses at the frequency of rotation $\Omega_0$ but also at every multiple of the gear meshing frequency $\Omega_{gmf}$. By experience all this phenomena stays in the audible range, so associated to frequency from $20Hz$ to $20kHz$.
	
	\textbf{TORQUE SPECTRUM}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	