\chapter{Continuous and discrete time Fourier Transform}
	
	Let's assume to have a continous signal $x(t) \in \mathds C$, we can define it's transform as
	\begin{equation}
		X(\Omega) := \int_{-\infty}^{\infty} x(t) e^{-j\Omega t} \, dt \quad \in \mathds C
	\end{equation}
	where $\Omega$ is a \textbf{frequency} expressed in radians. In general not all signal can be transformed. The discrete time counter-part, applied to a discrete signal $x(n) \in \mathds C$ (where $n\in \mathds Z$) using the normalized $x$ axes, is the discrete-time fourier transform defined as
	\begin{equation}
		X\left(e^{j\omega}\right) := \sum_{\infty}^{n = - \infty} x(n) e^{-j\omega n}
	\end{equation}
	where this time $\omega$ is not measured as $[rad/s]$, but it's just a pure number expressed in $[rad]$ (not divided by the time). In fact given the sampling time $T_s$ of the discrete signal, we can see the relation between $\Omega$ and $\omega$ as $\omega = \Omega T_s$. Notice that working with the variable $\omega$ is more general because the \textbf{\textit{spectrum}} generated by the transform isn't related to the sampling time $T_s$, but in a more general way.
	
	\paragraph{Inverse transform} Given a transform $X(\Omega)$ of a continuous-time signal, to retrieve back the function in the domain of time we need to use the \de{Fourier Inverse Transform} defined as
	\begin{equation}
		x(t) := \frac 1 {2\pi} \int_{-\infty}^\infty X(\Omega) e^{j\Omega t} \, d\Omega
	\end{equation}
	Given instead a discrete-time transform X(n), the definition of the inverse transform is done as
	\begin{equation}
		x(n) = \frac 1{2\pi} \int_{-\pi}^\pi X\left(e^{j\omega}\right) e^{j\omega n}\, d\omega
	\end{equation}
	and the integral definition is due the fact that $\omega$ is a continuous variable; the integrating range is defined as $[-\pi,\pi]$ cause the angle is a periodic function with period $2\pi$, and so integrating in a wider range won't give any new features to the signal.
	
	\paragraph{Relationship with other transforms} The Fourier transform is related to the Laplace transform defined as
	\[x(t) \xrightarrow{\mathscr{L}} X(s) := \int_{-\infty}^\infty x(t) e^{-st} \, dt \]
	where $s = \sigma + j\omega \in \mathds C$ is a complex variable. In general if the Laplace transform of a function exists, also the Fourier counter-part exists, because we can see the Fourier transform as
	\[ X(\Omega) = X(s) \big|_{s = j\Omega} \]
	so it's the frequency axes of the complex plane of the Laplace transform. In reality some function can have the Fourier transform even if the Laplace one cannot be computed.
	
	In the discrete time case the relation is between the Z transform $\mathscr{Z}$ defined as
	\[x(n) \xrightarrow{\mathscr{Z}} X(z) = \sum_{n=-\infty}^{\infty} x(n) z^{-n}  \qquad z \in \mathds C \]
	where $z$ is a complex variable. Comparing this transform with the discrete-time Fourier one, we can see that by replacing $z$ as $e^{j\omega}$ we can see that they are equal:
	\[ X\left(e^{j\omega} \right) = X(z) \big|_{z = e^{j\omega}}\]
	Considering that $|e^{j\omega}| = 1 \ \forall \omega$, this means that $e^{j\omega}$ represent a circle in the complex plane with unitary radius and $\omega$ is the angle that describes the point in the circle.
	
	\paragraph{Existence conditions of the Fourier transform} In general there's no guarantee that the integral/sum converges in order to get the transform; in particular we can define the \textbf{sufficient condition} (but not necessary) that says that if the signals $x(t), x(n)$ are absolutely summable (such that $\int_{-\infty}^\infty |x(t)|\, dt < \infty$, $\sum_{n=-\infty}^\infty |x(n)| < \inf $) then $X(\Omega), X(e^{j\omega})$ exists.
	\begin{proof}
		To prove this sufficient condition for the continuous time case, we need to consider that
		\begin{align*}
			|X(\Omega)| = \left| \int_{-\infty}^\infty x(t) e^{-j\Omega t}\, dt \right| \leq \int_{-\infty}^\infty |x(t)|\underbrace{ \left|e^{-j\Omega t}\right|}_{=1} \, dt
		\end{align*}
		So if the integral of $|x(t)|$ converges, also the Fourier transform exists.
	\end{proof}
	
	It's possible to have function that are not absolutely summable but for which the Fourier transform exists.
	
	\textbf{ESEMPIO DI INVERSIONE DI UNA TRASFORMATA RETTANGOLARE}
	
	A weaker necessary condition for the existence of the Fourier transform is that if $X(\Omega)$ (or $X(e^{j\omega})$) exists, than it's necessary that $x(t) = \lim_{\Omega \rightarrow \infty} \frac 1 {2\pi} \int_{-\Omega}^\Omega X(\Omega) e^{j\Omega} \, d\Omega $, or in a more general way the necessary condition of the existence of the transform is that the energy signal converges to a finite number (and so it's not divergent).
	
	\paragraph{Relationship between Fourier transform and series} 
	The Fourier transform and series are related, but are two different things: the \textbf{series} is the composition in the \textbf{time domain} of the components of the signal, while the \textbf{transform} changes the shape of the signal from time to \textbf{frequency domain}.
	
	By expressing the Fourier series with the complex notation
	\[ c_m = \frac 1 T \int_{-T/2}^{T/2} x(t) e^{-\frac{2\pi j m t}{T} } \, dt \]
	where $x(t)$ is a periodic function with period $T$; if we extract the signal in a period as
	\[\tilde x(t) = \begin{cases}
		x(t) \qquad & t \in [-T/2,T/2] \\ 0 & \textrm{otherwise}
	\end{cases} \]
	\[ \Rightarrow \quad \tilde X(\Omega) = \int_{-\infty}^{\infty} \tilde x(t) e^{-j\Omega t} dt = \int_{-T/2}^{T/2} \tilde x(t) e^{-j\Omega t} dt \]
	This equation allows us to express the coefficients $c_m$ by using the Fourier transform.
	
	
\section{Property of the transform}
	\begin{itemize}
		\item the Fourier transform is a \textbf{linear operator}, so for every signals $x_1(t),x_2(t)$ that has a transform associated, for every coefficients $a,b\in \mathds R$ it happens that
		\[ \mathscr{F} \big\{ a x_1(t) + b x_2(t) \big\} = a \mathscr{F}\big\{x_1(t)\big\} + b \mathscr{F}\big\{x_2(t)\big\}\]
		\begin{proof}
			To proof this property we have to use the linearity property of the integration:
			\begin{align*}
				\int_{-\infty}^\infty \Big(a x_1 (t) + bx_2(t)\Big) e ^{-j\Omega t} \, dt = a \int_{-\infty}^\infty x_1 (t)  e ^{-j\Omega t} \, dt + b \int_{-\infty}^\infty x_2 (t)  e ^{-j\Omega t} \, dt 
			\end{align*}
		\end{proof}
		
		\item \textbf{time shifting}: considering a signal $x(t)$ shifted in time axes by a value $t_0$ (such that $x \rightarrow x(t-t_0)$ ), than
		\[ \four{x(t-t_0)} = e^{-j\omega t_0} \four{x(t)} \]
		
		\item \textbf{convolution operation}: \textit{convolution} is an operation performed between signal that in the continuous time case defined for the signals $x,h$ like
		\[y(t) = x(t) * h(t) := \int_{-\infty}^\infty x(\tau) h(t-\tau)\, d\tau \]
		In the discrete time case the convolution is defined as $y(n) = x(n)*h(n) := \sum_{u=\infty}^\infty x(n) y(n-u)$. This operation allows us to determine the response of the system for every input by only knowing the impulse input. The property associated to the convolution states that
		\[ \four{x(t) * h(t)} = \four{x(t)} \four{h(t)} \]
		\begin{proof}
			\begin{align*}
				\four{x(t) * h(t)} & = \int_{-\infty}^\infty \left( \int_{-\infty}^\infty x(\tau) h(t-\tau)\, d\tau \right) e^{-j\Omega t} \, dt \\
				& =  \int_{-\infty}^\infty x(\tau) e^{-j\Omega \tau} \underbrace{\left( \int_{-\infty}^\infty h(t-\tau) e^{-j\Omega(t-\tau)} \, dt \right)}_{=\four{h(t)}} \, dt \\
				& = H(\Omega) \int_{-\infty}^\infty x(\tau) e^{-j\Omega \tau} \, d\tau = X(\Omega) H(\Omega)
			\end{align*}
		\end{proof}
	
		\item \textbf{differentiation in frequency property}: given a signal $x$ that has Fourier transform, then
		\[\four{t\, x(t)} = j \frac{d X(\Omega)}{d\Omega} \qquad \four{n \, x(n)} = j \frac{dX(e^{j\omega})}{d\omega} \]
		
		\begin{proof}
		\begin{align*}
			\sum_{n=-\infty}^\infty n x(n) e^{-j\omega n} & = \frac{-j}{-j}\sum_{n=-\infty}^\infty x x(n) e^{-j\omega n} \\
			& = j \sum_{n=-\infty}^\infty x(n) \frac{de^{-j\omega n}}{d\omega} \\
			& = j \frac{d}{d\omega}\sum_{n=-\infty}^\infty x(n) e^{-j\omega n} = j \frac{dX(e^{j\omega})}{d\omega}
		\end{align*}
		\end{proof}
		
		\item \textbf{symmetric property}: if $x(t)\in \mathds R$ is a real valued signal, than
		\[ X(-\Omega) = X^*(\Omega) \qquad X\big(e^{-j\omega}\big) = X^*\big(e^{j\omega}\big) \]
		\begin{proof}
		\begin{align*}
			X(-\Omega) & = \int_{-\infty}^\infty x(t) e^{-j (-\Omega) t} \, dt = \int_{-\infty}^\infty x(t) \left(e^{-j\Omega t}\right)^* \, dt \\ 
			& = \left( \int_{-\infty}^\infty x(t) e^{-j\Omega t} \, dt\right)^* = X^*(t)
		\end{align*}
		\end{proof}
		From this property we can state that the \textbf{magnitude spectrum} $|x(\cdot)|$ (and so the real part of the spectrum) is always an even function, while the \textbf{phase spectrum} $\angle x(\cdot)$ (thus the imaginary part of the spectrum) is an odd function. \vspace{3mm}
		
		As corollary to this property is that if the function $x(t)$ is real and even, it happens that $X(-\Omega) = X(\Omega)$ and the transform it's also inside the real domain (not the complex one).
		\begin{proof}
			Given the even function $x(t) \in \mathds R$ we can write
			\begin{align*}
				X(\Omega) & = \int_{-\infty}^\infty x(t) \overbrace{\big(\cos(\Omega t) + \cancel{j \sin(\Omega t)}\big)}^{e ^{-j\Omega t}} \, dt 
			\end{align*}
			Due to the fact that for an even function only the cosine part of the $e^{j\Omega}$ remains, this means that also the spectrum is real.
		\end{proof}
		Instead if the real function $x(t)$ is odd, than $X(\Omega)$ is purely imaginary.
		\begin{proof}
			Given the even function $x(t) \in \mathds R$ we can write
			\begin{align*}
				X(\Omega) & = \int_{-\infty}^\infty x(t) \overbrace{\big(\cancel{\cos(\Omega t)} + {j \sin(\Omega t)}\big)}^{e ^{-j\Omega t}} \, dt 
			\end{align*}
			Due to the fact that for an odd function only the sine part of the $e^{j\Omega}$ remains, this means that also the spectrum is real.
		\end{proof}
		In general every real function $x(t)$ can be decomposed into two function: an even one $x_e(t)$ and a odd one $x_o$ defined as
		\[ x_e(t) = \frac{x(t)+x(-t)}{2} \qquad x_o = \frac{x(t)-x(-t)}{2} \qquad \Rightarrow \quad x(t) = x_e(t)+ x_o(t) \]
		This means that the spectrum of every function can be subdivided in only real part (associated to $x_e$) and a purely imaginary part (associated to $x_o$):
		\[ X(\Omega) = \int_{-\infty}^\infty x_e(t) \cos(\Omega t) \, dt + j \int_{-\infty}^\infty x_o(t)\, \sin(\Omega t)\, dt = X_e(\Omega) - j X_o(\Omega)\]
	
		\item \textbf{time reversal property}: given a real/discrete signal $x(t),x(n)$, than the Fourier transform of the reversed function equals to the conjugate of the transform with reverse axes
		\[ \four{x(-t)} = X^*(-\Omega) \qquad \four{x(-n)} =X^*(e^{-j\omega}) \]
		In particular if the signal is real it also happens that $\four{x(-t)} = X^*(\Omega)$.
		\begin{proof}
			Dimostrazione mediante cambio di variable.
		\end{proof}
		
		\item \textbf{windowing theorem}: assume having to signal $x(t),w(t)$ (or $x(n), w(n)$ ) that produces the signal $y(t) = x(t) \, w(t)$ (note that this is not a linear operation), then the corresponding Fourier transform is the convolution (in the frequency domain) of the transforms:
		\[ Y(\Omega) = X(\Omega)*W(\Omega) = \frac 1 {2\pi} \int_{-\infty}^{\infty} X(\Theta) W(\Omega - \Theta)\, d\Theta \]
		\[ Y(e^{j\omega}) = X(e^{j\omega}) * W(e^{j\omega}) = \frac 1 {2\pi} \int_{-\pi}^\pi X(e^{j\theta}) W(e^{j(\omega-\theta)}) \, d\theta  \]
		
		This is important because when we analyse a signal, we are analysing only one portion (in time) of the signal itself, we never can scan the full length of the signal. Analytically speaking analysing the signal $x(t)$ in a certain range $T$ can be seen as the product of the full $x$ signal with a rectangle signal $w$ with value 1 in the sampling range and 0 elsewhere. In a practical way this means that by analysing only a set of the signal $x$ (and not the full one), we introduce a distortion (due to $w$) that can be \textit{measured} with the convolution operation.
		
		\begin{proof}
		\begin{align*}
			\sum_{n=-\infty}^\infty x(n) w(n) e^{-j\omega n} & = \sum_{n=-\infty}^\infty w(n) \left( \frac 1 {2\pi} \int_{-\pi}^\pi x\big(e^{j\theta}\big) e^{j\theta n} \, d\theta \right) e^{-j\omega n} \\
			& = \frac 1 {2\pi} \int_{-\pi}^\pi \left( X\big(e^{j\theta}\big) e^{j\theta n} \sum_{n=-\infty}^\infty w(n) e^{-j\omega n} \right) \, d\theta \\
			& = \frac 1 {2\pi} \int_{-\pi}^\pi \left( X\big(e^{j\theta}\big)  \sum_{n=-\infty}^\infty w(n) e^{-j(\omega-\theta) n} \right) \, d\theta \\
			& = \frac 1 {2\pi} \int_{-\pi}^\pi X\big(e^{j\theta}\big) W \big(e^{j(\omega - \theta)}\big) \, d\theta
		\end{align*}
		\end{proof}
		An important corollary to this property is the \textbf{Parsevals's theorem} that states that given two signals $x,y$, than it happens that
		\[ \four{\int_{-\infty}^\infty x(t) y^* (t)\, dt} = \frac 1 {2\pi} \int_{-\infty} ^\infty X(\Omega) Y^*(\Omega)\, d\Omega \]
		This is useful because if we calculate $\int_{-\infty}^\infty x(t)x(t)\, dt$ we get that the energy of the signal can be calculated also in the frequency domain.
		
		\item \textbf{correlation property} (in time): this values tends to measure the similarity between of two signals $x,y$ and it's define by the operator $\otimes$:
		\[ x(t) \otimes y(t) = \int_{-\infty}^\infty x(\tau) y^*(t+\tau)\, d\tau = x(t)*y^*(-t) \]
		Note that in general if we calculate the correlation between the same function ($x\otimes x$), that measures the \textbf{autocorrelation}.
		
		In general we can use the property of the transform of a correlated signal as
		\[ \four{x(t)\otimes y(t)} = \frac 1{2\pi} \int_{-\infty}^\infty X(\Omega) Y^*(\Omega) e^{j\Omega t} \, d\Omega  \]
		The proof of this property can be done by using the Parsevals's theorem.
	\end{itemize}
	
	\subsection{Remarkable examples of Fourier transforms}
		\begin{align*}
			\four{\delta(t)} & = \intinf \delta(t) e^{-j\Omega t}  \, dt = e^{-j\Omega 0} \\ & = 1 \\
			\Rightarrow \quad \four{\delta(t - t_0)} & = e^{-j\Omega t_0}
		\end{align*}
		\begin{align*}
			\four{A \, \textrm{rect}_\tau(t)}	& =	 A \int_{-\tau/2}^{\tau/2} e ^{-j\Omega t} \, dt = \frac \tau 2 A \frac{e^{-j\Omega \tau/2} - e^{j\Omega \tau/2}}{-j\Omega \frac \tau 2} \\ & = A \tau \sinc (\Omega \tau/2) \\
			\four{a} & = a \, \delta(\Omega)
		\end{align*}
	
		In a general way we can use the \de{duality principle} for which it happens that $x(t) \xrightarrow{\mathscr{F}} X(\Omega)$ leads to $X(t) \xrightarrow{\mathscr{F}} x(-\Omega)$ and $x(\Omega) \xrightarrow{\mathscr{F}} X(-t)$.
	

	
	
	
	
	
	
	